# Note

> For my own convenience, I will write this note in Chinese
>
> Maybe I'll translate it to English later...

## 优化和搜索

> Optimization and Search

### 梯度下降

- 原理
  - 求目标函数 $f(x)=f(x_1,...,x_n)$ 极小值
  - 迭代：$x^{i+1}_k=x^i_k-\eta\frac{\partial f}{\partial x_k}(x_k^i)$
    - 找到下降最快的方向下降，这个方向就是求偏导的方向
- 梯度下降法
  - 基于学习率的改进机制
    - 希望当梯度值很大时，更新较小
    - 将学习率除以梯度值
    - 平方开根，保证为正
  - 冲量法
    - 当本次梯度下降的方向与上次更新量方向相同时，上次的更新量对本次更新起加速作用，否则起减速作用
    - 由于向量本身就携带方向的信息，所以公式中直接加上加权值即可
    - $v_t=\gamma v_{t-1}+\eta\frac{\partial f}{\partial\theta}(\theta_{t-1})$
    - $\theta_{t+1}=\theta_t-v_t$
  - NAG
    - 比冲量法更多地考虑了梯度变化的幅度，通过下一个近似位置来更新，可以避免更新过猛
    - $v_t=\gamma v_{t-1}+\eta\frac{\partial f}{\partial\theta}(\theta_t-\gamma v_{t-1})$
    - $\theta_{t+1}=\theta_t-v_t$
  - 自适应梯度下降法
    - 学习率适应梯度，越往后学习率越小
    - $\theta_{t+1}=\theta_t-\frac{\eta}{S_t+\varepsilon}\frac{\partial f}{\partial\theta}(\theta_t)$
    - $S_t=S_{t-1}+[\frac{\partial f}{\partial\theta}(\theta_t)]^2$

### 最小二乘法

- 误差平方和 $S=\frac{1}{2}\sum(f(x_i)-y_i)^2$
  - $f(x)$ 是你的目标函数
  - $y$ 是真实值
- 将其表示为矩阵的形式 $S(\theta)=\frac{1}{2}||X\theta-y||^2$
  - $x_i=[x_{1i},...x_{ni}]$，$X=[x1^T,...,x_m^T]$，代表  $m$ 个 $n$ 维样本
  - $\theta=[\theta_1,...,\theta_n]$，代表 $n$ 个参数
  - $y=[y_1,...,y_m]$
- 要确定 $f(x)$，就要找到最好的 $\theta$，就要最小化 $S(\theta)$
- 推导过程
  - $S(\theta)=\frac{1}{2}(X\theta-y)^T(X\theta-y)$
  - 求导：$\frac{\partial S}{\partial\theta}=0$
    - 公式
      - $\frac{\partial}{\partial X}X^TA=A$
      - $\frac{\partial}{\partial X}X^TAX=(A+A^T)X$
      - $\frac{\partial}{\partial A}X^TAy=X^Ty$，$\frac{\partial}{\partial A}X^TA=X^T$
      - $\frac{\partial}{\partial X}A^{-1}=-A^{-1}\frac{\partial A}{\partial X}A^{-1}$
    - 过程
      - $\frac{\partial S}{\partial\theta}=\frac{\partial}{\partial\theta}\frac{1}{2n}(\theta^TX^TX\theta-2y^TX\theta+y^Ty)=0$
      - $\frac{1}{2n}(2X^TX\theta-2X^Ty)=0$
      - $X^TX\theta=X^Ty$
      - $\theta=(X^TX)^{-1}X^Ty$
  - 通过这个式子就可以求解 $\theta$ 了
    - $X$ 必须满秩，$X^TX$ 必须是非奇异矩阵，否则就无法求解 $(X^TX)^{-1}$

### 最大似然估计

- 似然函数
  - $P(x|\theta)$：$x$ 是样本，$\theta$ 是模型（参数）
  - 当 $\theta$ 已知的时候叫做 **概率函数**，表示样本 $x$ 出现的概率
  - 当 $x$ 已知而 $\theta$ 未知的时候，这个函数叫做 **似然函数**，等价于 $L(\theta|x)$，表示在某个模型 $\theta$ 下 $x$ 出现的概率
- 最大似然估计
  - 我们现在希望找到 $\theta$ 使得 $x$ 出现的概率最大，这个 $\theta$ 就代表了最接近真实的模型
  - 假设我们有样本集 $X=x_1,...,x_n$
  - 那么就要使 $L(\theta|X)=\prod_{i=1}^nP(x_i|\theta)$ 最大
  - 为了方便计算，取对数得到 $ln[L(\theta|X)]=\sum_{i=1}^nln[p(x_i|\theta)]$
  - 然后将其对每一个 $\theta$ 的分量求偏导等于 $0$，解方程组即可
    - **疑问：这个过程能用程序解决吗？**
- 当误差服从正态分布时，最大似然估计等价于最小二乘法

## 维度约简

> Dimension reduction

- 目的
  - 减少计算成本
  - 去除噪声
  - 使结果更容易理解（可视化）

### LDA

- 线性判别分析
- 推导
  - 假设数据集中心为 $u$，样本点为 $x$，类为 $c$
  - 每个类的协方差：$\sum_{j\in c}(x_j-u)(x_j-u)^T$
  - 每个类的概率：$p_c=\frac{n_c}{n_总}$
  - 组内分布：$S_w=\sum_{c}\sum_{j\in c}p_c(x_j-u_c)(x_j-u_c)^T$（越小越好）
  - 组间分布：$S_b=\sum_c(u_c-u)(u_c-u)^T$（越大越好）
  - 将它们结合起来就得到了这样一个值 $\frac{S_b}{S_w}$
  - $\frac{S_b}{S_w}$ 将指导我们在降维时怎么做对数据来说才是好的（越大越好）
  - 降维要用到投影，我们知道数据点 $x$ 在向量 $w$ 上的投影是 $w^Tx$
  - 尝试用 $w^Tx_j$ 替换 $x_j$，那么 $\frac{S_b}{S_w}=\frac{w^TS_ww}{w^TS_bw}$
  - 为了找到以 $w$ 为变量的最大值，我们对 $w$ 求导，得到 $\frac{S_bw(w^TS_ww)-S_ww(w^TS_bw)}{(w^TS_ww)^2}$
  - 令导数为 $0$，化简得 $S_ww=\frac{w^TS_ww}{w^TS_bw}S_bw$
  - 然后通过计算 $S_w^{-1}S_b$ 全部的特征值以及特征向量得到 $w$ 的值
- 算法
  - 按上述过程得到  $S_w^{-1}S_b$ 的全部特征值以及特征向量
  - 假设原数据有 $d$ 个特征，我们可以选取最大的 $k$ 个特征值对应的特征向量，构造一个 $d\times k$ 的矩阵，这个矩阵就可以将样本映射到 $k$ 维空间

### PCA

- 主成分分析
- 用来降维无标签数据（LDA 处理有标签数据）
- 思想
  - 寻找更好的坐标系
- 如何寻找
  - 主成分：数据中变化最大的方向
  - 首先通过减去平均值将数据集中
  - 然后选择变化最大的方向将其设为坐标轴
  - 检查余下的变化，找到另一个坐标轴，正交与已有坐标轴，且变化最大
  - 重复，直到剩余的坐标系中数据的变化很小，可以直接抛弃，这就达到了降维的效果
- 推导
  - 基变换
    - 假设有正交基 $a_1=(a_{11},a_{12}),a_2=(a_{21},a_{22})$，有数据点 $x=(x_1,x_2)^T$
    - $x$ 在 $a_1,a_2$ 坐标轴上的坐标为 $(a_1,a_2)^Tx$
    - 如果基数量小于 $x$ 维度，就可以实现降维
      - 但是，要如何选择基呢？结合上文所述，我们要寻找变化最大的方向
  - 所谓变化最大其实就是数据点尽可能分散，而这种分散程度可以用方差表示
    - $Var(x)=\frac{1}{n}\sum_{i=1...n}(x_i-\overline{x})^2$
    - 如果我们令每一个样本点都减去均值中心化，则有 $Var(x)=\frac{1}{n}\sum x_i^2$
  - 同时，按照上面的说法，我们还要让两个方向正交，这可以用协方差为 0 表示
    - $Cov(a,b)=\frac{1}{n}\sum_{1...n}a_ib_i=0$
    - 而且，应该优先满足正交，在此基础上去寻找方差最大的数个方向
  - **协方差矩阵**
    - 现在，我们要通过数学的方法同时满足协方差的要求并计算方差
    - 恰好，协方差矩阵能够将两者完美地统一在同一个矩阵中
    - 对于 $N$ 个 $M$ 维的数据 $x_i=(x_{i1},...x_{iM})^T$，将其写成 $M\times N$ 的数据矩阵 $X=(x_1,...x_N)$，协方差矩阵为 $\frac{1}{N}XX^T=C$
      - $C_{jj}$ 是第 $j$ 个特征的方差
      - $C_{ij}$ 是低 $i$ 个特征和第 $j$ 个特征的协方差
  - 协方差矩阵对角化
    - 现在，我们要让协方差全部为 0，这就等于让协方差矩阵对角化
    - 协方差矩阵是一个对称矩阵，那么它具有这样的性质
      - **这里的证明暂略**
      - $M\times M$ 的实对称矩阵一定可以找到 $M$ 个单位正交特征向量
    - 假设我们已经算出了特征向量矩阵 $E$，那么有 $E^TCE=特征值对角阵$
    - 又假设我们最后得到的基矩阵为 $P$，令 $Y=PX$，即降维后的数据矩阵，则 $Y$ 的协方差矩阵 $D$ 是一个对角阵
    - 因为 $D=\frac{1}{N}YY^T=\frac{1}{N}(PX)(PX)^T=\frac{1}{N}PXX^TP^T$$=P(\frac{1}{N}XX^T)P^T=PCP^T$
    - 结合上面 $V^TCV$ 为对角阵，所以  $P=V^T$，那么最终我们就得到了这个基矩阵
- 算法
  - 将 $N$ 个数据 $x_i=(x_{i1},...,x_{iM})^T$ 写成 $M\times N$ 的矩阵 $X$
  - 通过减去每列的平均值将数据中心化，得到矩阵 $B$
  - 计算协方差矩阵 $C=\frac{1}{N}B^TB$
  - 计算 $C$ 的特征值和特征向量，即 $V^{-1}CV=D$，$V$ 为特征向量矩阵，$D$ 为 $M\times M$ 阶对角矩阵，由特征值组成
  - 将 $D$ 对角线上的元素降序排列，$V$ 同步
  - 去掉那些小于指定值的特征值，剩下 $L$ 列特征向量矩阵 $K$
  - $P=K^T$
  - 通过 $Y=PX$ 降维原数据到 $L$ 维

### ICA▲

- 独立成分分析
- 盲源分离问题
  - 假设所有的数据都来自一些独立的物理过程
  - 但我们所看到的数据是这些过程的数据的输出方式被混在了一起
  - 我们想做的就是把这些混合的数据变成多个独立源
- 举例：鸡尾酒会问题
  - 从多个收集器的多人重叠声音中提取出不同人的声音
  - 假设有两个数据源产生声音 $s_1^t$ 和 $s_2^t$（上标 $t$ 表示数据与时间有关）
  - 则两个收集器的声音表示为 $x_1=as_1+bs_2,x_2=cs_1+ds_2$
  - 可以用矩阵的形式将其写作 $x=As$，$A$ 称为混合矩阵
  - 我们要求的其实就是 $s=A^{-1}x$
  - 现在要明确几点
    - 混合数据并不是独立的，尽管数据源之间是独立的
    - 混合数据可以服从高斯分布（中心极限定理）
    - 数据源必须是非高斯变量，否则不满足独立性要求
  - 学不下去了...

## 

## 演化学习

> Evolutionary Learning

### 遗传算法

- 启发：生物进化
- 与假设搜索的区别
  - 假设搜索：一般到特殊，简单到复杂
  - 遗传算法：通过对当前最好的模型重组来产生后续的假设模型
- 一般形式
  - 初始化 $t=0$，初始化种群 $P(t)$
  - 如果 不满足终止条件
    - 评估 $P(t)$ 中每个染色体的适应度
    - 通过某种规则选择部分染色体
    - 根据所选染色体产生后代
    - 根据 $P(t)$ 中染色体的适应度选择被替换的染色体，用后代染色体替换
    - $t=t+1$
  - 终止
- 种群：一组染色体及其适应度
  - 初代种群随机选取
- 如何表示染色体（个体）：编码
  - 常用：二进制编码
    - 可以应用 **模式理论**（见下）
  - 单属性
    - $n$ 种值用 $n$ 个 $1|0$ 表示
  - 决策属性
    - 用一位 $0|1|\#$，$\#$ 表示 $0\or1$
- 什么是适应度函数
  - $fit(染色体)=适应度$
  - 用于评估染色体的价值
- 怎样产生后代
  - 选择算子：选择一定数量的优秀染色体
    - 锦标赛选择
      - 每次从种群中取出一定数量的染色体（放回抽样），挑选其中最好的一个进入后代，重复
    - 截断选择
      - 根据适应度排序，前 $F$ 个染色体进入后代
    - 轮盘赌选择
      - **聚类-kmeans++ 中有介绍轮盘法**
      - 被选到的几率与适应度成正比
  - 遗传算子：对选中的染色体进行重组以产生后代
    - 单点交叉：随机选取一个交叉点，将交叉点后的染色体部分互换
      - $10$ $01\times11$ $10\rightarrow1101,1010$
    - 两点交叉：随机选取两个交叉点，随机将部分基因交换
    - 均匀交叉：基因的每个位置都以相同的概率进行交换
  - 变异
    - 随机选择某个染色体的某一位进行取反（概率为 1/染色体长度）
    - 避免局部收敛
- 后代替换父代的策略
  - 简易法
    - 后代种群直接替代父代种群
    - 易丢失优秀解
  - 精英法
    - 保留父代最优个体，丢弃后代最差个体
    - 与选择算子混用
  - 锦标赛法
    - 后代选择父代最差的几个取而代之
  - 小生境法
    - 将每一代划分为若干类
    - 在每个类中选出若干适应度较大的个体作为一个类的代表
    - 再在不同类之间交叉和变异产生后代
    - 选择机制▲
      - 预选择机制：只用高适应度的后代替换父代
      - 排挤机制：预定义一个原型，所产生的的后代如果与原型一致就不替换
      - 共享机制：计算适应度和模式的关联关系，然后共享这种模式
- 优点
  - 无需理解问题内部的相关性
  - 从一个随机种群开始，以适应度作为启发
- 问题
  - 表示问题：编码不规范，编码表示的不准确性
  - 约束问题：单一的遗传算法编码不能全面地将优化问题的约束表示出来
  - 效率问题：效率较低，容易出现过早收敛
  - 理论问题：对算法的精度，可行度，计算复杂度等难以定量计算

### 模式理论

- 模式定理：低阶、短长度、适应度高于种群平均适应度的模式将会在进化中增加表示
- 定义
  - 模式：$0|1|\#$ 组成的任意串
  - 阶
    - 确定位置的个数
    - $o(\#\#1\#0)=2$
  - 长度
    - 第一个确定位置到最后一个的距离
    - $d(\#\#1\#0)=2$
- 怎样证明这个定理
  - 符号定义
    - $m(s,t)$ ：第 $t$ 代种群中模式 $s$ 的实例数量
    - $f(h)$：染色体 $h$ 的适应度
    - $\overline{f}(t)$：第 $t$ 代种群的平均适应度
    - $n$：种群中个体总数
    - $h\in s\bigcap p_t$：染色体 $h$ 符合模式 $s$ 且属于种群 $p_t$
    - $\overline u(s,t)$：第 $t$ 代符合模式 $s$ 的染色体的平均适应度
    - $p_c$：单点交叉概率
    - $p_m$：任一染色体位变异的概率
    - $l$：染色体长度（不是模式长度！）
  - 目标：推断 $m(s,t+1)$ 的期望
  - 推导▲
    - 选择 $h$ 的概率 $Pr(h)=\frac{f(h)}{n\overline{f}(t)}$
    - 选择的染色体是模式 $s$ 的概率 $Pr(h\in s)=\frac{\sum_{h\in s\bigcap p_t}f(h)}{n\overline{f}(t)}=\frac{\overline{u}(s,t)*m(s,t)}{n\overline{f}(t)}$
    - 如果只考虑选择 $n$ 次，得到 $s$ 的实例的期望为 $E[m(s,t+1)]=\frac{\overline{u}(s,t)*m(s,t)}{\overline{f}(t)}$
    - 交叉后仍属于模式 $s$ 的概率 $1-p_c\frac{d(s)}{l-1}$
    - 变异后仍属于模式 $s$ 的概率（确定位都不变）： $(1-p_m)^{o(s)}$
    - 引入交叉和变异后有 $E[m(s,t+1)]\geq \frac{\overline{u}(s,t)*m(s,t)}{\overline{f}(t)}(1-p_c\frac{d(s)}{l-1})(1-p_m)^{o(s)}$
    - 从这个式子可以看出
      - 低阶（$o(s)$ 小）
      - 短长度（$d(s)$ 小）
      - 适应度高（$\overline{u}(s,t)$ 大）
      - 这样的模式影响力大

### 其它▲

- 自然计算
  - 模仿自然界，具有自适应、自组织、自学习能力的模型与算法
  - 往往用来解决非凸优化问题
- 粒子群优化
- 蚁群优化
- 学习分类器

## 树学习

> Tree Learning

### 概念学习

- 概念：给定样例集合，以及每个样例属于某个概念，自动推断出概念的一般定义
- 定义
  - 实例集合 $X$：每个实例 $x$ 用 $n$ 个属性表示
  - 目标概念 $c$：一个布尔函数 $c(x)=0|1$
  - 训练样例：正/反例 即判断实例是否属于这个概念，表现为 $c(X)=0|1$
  - 假设 $h$：也是一个布尔函数，我们要找到一个 $h$ 使得对 $X$ 中所有 $x$ 都有 $h(x)=c(x)$
- 确定假设表示
  - 假设我们的实例可以用 6 个属性表示，那么
    - 最一般的假设表示为 \<?,?,?,?,?,?\>​
    - 最特殊的假设表示为 <\$,\$,\$,\$,\$,\$>
  - 这样的假设就像是一个正则表达式，能正确匹配更多实例的假设，我们就称为 **更泛化** 的假设
  - 之后，我们的任务就变成了 **搜索** 能够最好拟合样例的假设
- 如何搜索？
  - 请看接下来的算法

#### Find-S

1. 将 $h$ 初始化为最特殊的假设 <\$,\$,\$,\$,\$,\$>
2. 对每个正例 $x$（即 $c(x)=1$）
   1. 对 $h$ 的每个属性 $a_i$
      1. 如果 $x$ 不满足 $a_i$，则将 $a_i$ 替换为 $x$ 能满足的最一般的约束
3. 输出 $h$

```
举例
X = [
	<S,W,N,S,W,S> Y,
	<S,W,H,S,W,S> Y,
	<R,C,H,S,W,S> N,  // 反例,不考虑
	<S,W,H,S,C,C> Y
]

h = <$,$,$,$,$,$> 不满足 X1[0~5], 替换为 <S,W,N,S,W,S>
h = <S,W,N,S,W,S> 不满足 X2[2], 替换为 <S,W,?,S,W,S>
h = <S,W,?,S,W,S> 不满足 X4[4][5], 替换为 <S,W,?,S,?,?>
输出 h = <S,W,?,S,?,?>
```

- 缺陷：只利用了正例

#### 列表消除算法

> 可不看，在现实中往往不可能列出所有假设

- 基本概念
  - 一致：假设 $h$ 与训练样例集合 $X$ 一致当且仅当对全部 $X$ 中的 $x$ 有 $h(x)=c(x)$
  - 变形空间：假设空间 $H$ 和 $X$ 的变形空间，是指 $H$ 中所有与 $X$ 一致的 $h$ 组成的集合，写作 $VS_{H,X}$
- 算法
  - 初始化变形空间，包含 $H$ 中全部假设
  - 对每个训练样例，从变形空间中移除不满足 $h(x)=c(x)$ 的 $h$
  - 输出剩余的假设列表

#### 候选消除算法

- 基本概念
  - 极大泛化：集合 $G$ = { \<?,?,?,?,?,?\> }
    - 反例用于缩小 $G$
  - 极大特化：集合 $S$ = { <\$,\$,\$,\$,\$,\$> }
    - 正例用于搜索 $S$
- 算法▲
  - 初始化 $G$，$S$
  - 对每个样例 $x$
    - 如果 $x$ 是正例
      - 从 $G$ 中移除所有与 $x$ 不一致的假设
      - 对 $S$ 中每个与 $x$ 不一致的假设 $s$
        - 从 $S$ 中移除 $s$
        - 把 $s$ 的所有极小泛化假设 $h$ 加入 $S$ 
          - $h$ 满足与 $X$ 一致且 $G$ 中的某个成员比 $h$ 更一般
    - 如果 $x$ 是反例
      - 从 $S$ 中移除所有与 $x$ 不一致的假设
      - 对 $G$ 中每个与 $x$ 不一致的假设 $g$
        - 从 $G$ 中移除 $g$
        - 把 $g$ 的所有极小特化假设 $h$ 加入 $G$
          - $h$ 满足与 $X$ 一致且 $S$ 中某个成员比 $h$ 更特殊
- 算法理解
  - 对正例，按照 Find-S 更新 $S$，同时要保证 $G$ 能够包含 $S$（意味着可能要删除一些 $g$）
  - 对反例，寻找样例与 $S$ 不一样的地方，用最泛化但能使得样例结果为反的形式加入 $G$
  - 最后对 $S$ 和 $G$ 中的假设做一个综合，得到除 <全 ?> 外能符合它们的全部假设

```
举例
X = [
	<S,W,N,S,W,S> Y,
	<S,W,H,S,W,S> Y,
	<R,C,H,S,W,C> N,
	<S,W,H,S,C,C> Y
]
初始化
G = {<?,?,?,?,?,?>}  S = {<$,$,$,$,$,$>}
X1
S = <S,W,N,S,W,S> (类似 Find-S)
X2
S = <S,W,?,S,W,S> (类似 Find-S)
X3
G = {<S,?,?,?,?,?>,<?,W,?,?,?,?>,<?,?,?,?,?,S>} (发现前两个和最后一个不一致)
X4
S = <S,W,?,S,?,?> (类似 Find-S)
G = {<S,?,?,?,?,?>,<?,W,?,?,?,?>} (为了保持 G 覆盖 S 移除最后一个)
最后形成的假设
<S,W,?,S,?,?>
<S,W,?,?,?,?>,<S,?,?,S,?,?>,<?,W,?,S,?,?>
<S,?,?,?,?,?>,<?,W,?,?,?,?>
共 6 个
```

### 归纳偏置

- 合取和析取
  - 我们上面使用的假设是合取式，只能包含 **?/属性 a/$**，但对于 **属性 a 或属性 b** 这样的表示无能为力
  - 这就导致合取的假设空间是 **有偏** 的，目标概念可能不在假设空间中
- 有偏和无偏
  - 假设上面的六个属性分别有 3,2,2,2,2,2 种取值
    - 则无偏空间共有 $2^{3*2*2*2*2*2}=2^{96}$ 种实例
    - 而有偏空间只有 $全\$ +(*|3种属性)*(*|2种属性)...=1+4*3*3*3*3*3=973$ 种假设
- 无偏学习的无用性
  - 那么是不是应该进行无偏学习？
  - 首先，无偏空间太大，搜索非常费时
  - 其次，无偏学习无法泛化，必须提供全部样例，才能够得到单个目标概念
  - 所以说，无偏学习是不可能实现的
- 归纳偏置
  - 核心：学习器从训练样例中泛化并推断新实例分类过程中采用的策略
  - 学习器如果不对目标概念的形式做预先的假定，它从根本上无法对未见实例进行分类
    - 在上面的例子中，我们的假定就是 可以用属性的合取表示目标概念
    - 预先的假定要与实际问题相切合
  - 最简单的归纳假设：奥卡姆剃刀
    - 如果对于同一现象有两种不同的假说，应该采取更简单的那一种  
- 不同的归纳偏置
  - 候选消除算法
    - 有偏（假设 $c\in H$）
  - FIND-S
    - 有偏性更强（假设 $c\in H$，且认为任何实例除非可由其它先验推出，否则为反例）
  - 有偏性越强，学习器的归纳能力越强

### ID-3 决策树

- 决策树
  - 实例以 属性-值 的形式表示
  - 健壮性（可以包含错误样例，缺少属性值的样例）
  - 能学习析取式
- 归纳偏置
  - 优先选择较小的树
- 算法：$ID3(Examples,Attributes)$
  - 创建根节点 $Root$
  - 如果 $Examples$ 全为 $+$，返回 $Root=+$
  - 如果 $Examples$ 全为 $-$，返回 $Root=-$
  - 如果 $Examples$ 全为空，返回 $Root= Examples$ 中最普遍的属性
  - 从 $Attributes$ 中挑选对 $Examples$ 分类能力最好的属性 $A$（见下）
  - 对于 $A$ 每个可能的值 $v_i$
    - 挑选出 $Examples$ 中满足 $A=v_i$ 的子集 $Examples_{v_i}$
    - 如果 $Examples_{v_i}$ 为空，增加一个由 $A=v_i$ 走到的子结点，label 为 $Examples$ 中最普遍的属性
    - 否则，增加一个由 $A=v_i$ 走到的子树 $ID3(Examples_{v_i},Attributes-A)$
  - 返回 $Root$
- 如何选择分类能力最好的属性
  - 要求给定的属性最能区分样例：信息增益（看这个属性能为分类带来多少信息）
  - 样例集合 $S$ 的信息熵
    - $E(S)=-p_+log_2p_+-p_-log_2p_-$
    - 比如，一个拥有 9 正例 5 反例的 $S$ 有 $E([9_+,5_-])=-(\frac{9}{14})log_2(\frac{9}{14})-(\frac{5}{14})log_2(\frac{5}{14})$
    - 若 $S$ 中所有样例属于同一类，则 $E(S)=0$
  - 样例集合 $S$ 关于属性 $A$ 的信息增益
    - $Gain(S,A)=E(S)-\sum_{v_i\in A}\frac{|S_{V_i}|}{|S|}E(S_{v_i})$
    - $S_{v_i}$ 是指 $S$ 中 $A=v_i$ 的子集
- 归纳偏置
  - 搜索的策略体现了归纳偏置
  - 优先选择信息增益较大的 $\rightarrow$ 优先选择较小的树
- 特点
  - 假设空间：包含所有决策树
  - 遍历过程：只维持一种假设（不像候选消除算法一样维持所有满足的假设）
  - 回溯：不进行回溯（贪心，局部最优）
  - 基于统计：对错误样例不敏感，不适用于增量处理
    - 改进算法

### 其它算法

| 算法 | 支持模型  | 树结构 | 特征选择       | 连续值处理 | 缺失值处理 | 剪枝   |
| ---- | --------- | ------ | -------------- | ---------- | ---------- | ------ |
| ID3  | 分类      | 多叉树 | 信息增益       | 不支持     | 不支持     | 不支持 |
| C4.5 | 分类      | 多叉树 | 信息增益比     | 支持       | 支持       | 支持   |
| CART | 分类&回归 | 二叉树 | 基尼系数均方差 | 支持       | 支持       | 支持   |

#### C4.5

- 问题
  - 信息增益（ID-3）偏向于选择属性取值数量较大的属性
  - 比如一个只有 10 个样例的 $S$，有属性 $A$ 取值为 $x_1,..,x_{10}$，每个取值仅有一个样例
    - 于是 $E(S_{v_i})$ 全为 0，信息增益显然最大，但这样的划分没有意义，十个样例全被单独划分开
- 解决：采用 **信息增益比** 作为特征选择标准
  - $SplitInfo(S,A)=-\sum_{v_i\in A}\frac{|S_{v_i}|}{|S|}*log_2(\frac{|S_{v_i}|}{|S|})$
  - $GainRatio(S,A)=\frac{Gain(S,A)}{SplitInfo(S,A)}$
  - 选择信息增益比最大的属性
- 思考
  - 但也要避免对可取值数目较少的属性有所偏好
  - 可以考虑：先从候选属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的

#### CART

- 问题
  - 前两种算法都需要计算 $log$
- 解决：基尼系数
  - 属性划分训练集的不纯度，越小越好
  - $Gini(S,A)=1-\sum_{v_i\in A}(\frac{|S_{v_i}|}{|S|})^2$
- 回归（略）

#### 连续值的离散化

- 假设 $m$ 个样本的连续特征 $A$ 从小到大为 $a1,...,a_m$
- 取每两个相邻样本间的平均值作为划分点 $T_i=\frac{a_i+a_{i+1}}{2}$
- 对每个 $T_i$，计算度量值（C4.5-信息增益比，CART-基尼系数）
- 选择度量值最小的 $T$ 作为离散分类点，小于其的为类别 1，大于其的为类别 2

#### 离散值处理

- 多叉树：ID3，C4.5 等，直接构建多叉树即可
- 二叉树：CART
  - 对 $A=A_1|A_2|A_3$，二分成 $A_1,(A_2,A_3)$；$A_2,(A_1,A_3)$；$A_3,(A_1,A_2)$ 这三种，找到基尼系数最小的组合，建立二叉树节点，比如选择了 $A_2,(A_1,A_3)$
  - 再继续划分 $A_1,A_3$

#### 剪枝处理▲

- 后剪枝
  - 目的：从完全的决策树底端剪去一些子树，使得模型更简单，泛化能力更强
  - 过程：从完整决策树 $T_0$ 开始不断剪枝得到子树 $T_1,...$；然后通过交叉验证测试，选择最优子树
  - 损失函数
    - $C_a(T)=C(T)+a|T|$
    - $C(T)$ 为该子树对数据的预测误差，如基尼系数
    - $|T|$ 为子树 $T$ 的叶结点个数
    - $a$ 为参数，权衡拟合程度与模型复杂度（$a$ 大，最优子树就小）

### 总结

- 树学习优点
  - 直观，容易理解
  - 基本不需要预处理，可以处理连续/离散，空缺值
  - 可以处理多维度分类问题
  - 代价为 $O(log_2m)$，$m$ 为样本个数
- 树学习缺点
  - 很容易过拟合，泛化能力弱
    - 设置节点最少样本树
    - 限制深度
    - 剪枝
  - 会因为样本的细微改动造成树的大幅度动荡
    - 集成学习改善
  - 寻找最优的决策树很难，容易陷入局部最优
    - 集成学习改善
  - 比较复杂的关系（如 异或），难以使用决策树学习
    - 用其它算法解决
  - 如果某些特征的样本比例过大，生成的决策树容易偏向于这些特征
    - 调节样本权重

## 强化学习

> Reinforcement Learning

### 概述

- 介于监督和无监督之间
  - 仅告知答案是否正确，不告诉学习者如何优化
  - 学习者要尝试不同的策略来挑出最好的
  - 奖赏最大化
- 智能体 $\rightarrow$ 行为 $\rightarrow$ 环境 $\rightarrow$ 状态&奖赏 $\rightarrow$ 智能体
  - 奖赏延迟：很长一段时间之后才会得到奖赏
  - 策略：在当前状态中选择行为
-  本质：奖惩和试错（Trail and Error）

### MDP

- 马尔科夫决策过程：Markov Decision Process
- 马氏性
  - 下一个决策只与当前状态和选择的行为有关
  - 与如何来到当前状态（历史）无关
- 定义
  - $S$：状态集合
  - $A$：动作集合
  - $\delta(s,a,s')$：状态 $s$ 采取动作 $a$ 转移到状态 $s'$ 的概率
  - $R(s,a)$：状态 $s$ 采取动作 $a$ 的即时奖赏
  - $\pi:S\rightarrow A$：策略，状态到动作的映射
  - 轨迹：一次完整迭代的经验（状态、动作、奖赏的一条链）
  - 返回值：将多个即时奖赏组合成单个值
    - 通常是线性组合
    - 要不要考虑早晚期的奖赏哪个更重要？
      - 折扣因子： $\gamma$
      - $G=\sum_i\gamma^iR_i$
- 问题：如何求解马尔科夫决策过程？
  - 动态规划

### 动态规划

- 前提：给定了一个 **完全已知** 的 MDP 模型
- 要做的事
  - 策略评估：给定策略 $\pi$，评估其返回值
  - 最优控制：寻找最优策略 $\pi^*$（从任一状态出发，返回值都最大）
- 值函数
  - 状态价值：$V^\pi(s)$：从状态 $s$ 出发，采用 $\pi$ 策略，所获得的返回值
  - 行动价值：$Q^\pi(s,a)$：从状态 $s$ 出发，采用 $a$ 动作和 $\pi$ 策略，所获得的返回值
  - $\pi^*$ 为最优策略当且仅当
    - $V^{\pi^*}(s)=max_\pi V^\pi(s)$
    - $V^\pi(s)=max_a Q^\pi(s,a)$
- 策略评估
  - $Bellman$ 等式
  - $V^\pi(s)=E[R(s,\pi(s))]+\gamma\sum_{s'}\delta(s,\pi(s),s')V^\pi(s')$
    - 所有值函数构成了一个公式组，需要用线性规划求解
    - 用数学期望 $E[...]$ 的原因是 $\pi(s)$ 是随机的
- 最优控制
  - $Q^\pi(s,a)=E[R(s,a)]+\gamma\sum_{s'}\delta(s,a,s')V^\pi(s')$
- 策略更新
  - 贪心
    - $\pi(s)=a_{max(Q^\pi(s,a))}$
  - $\varepsilon$ - 贪心
    - $\varepsilon$ 的概率选择其它动作
    - $1-\varepsilon$ 的概率贪心
- 迭代方法
  - 初始化 $\pi_0$
  - 策略评估得到 $V^{\pi_0}$
  - 通过最优控制得到 $\pi_1$
  - 直至收敛得到 $\pi^*$
- 问题：当 MDP 模型非已知（大多数强化学习问题都是如此）的时候，要怎么进行求解呢？
  - Monte Carlo 方法

### Monte Carlo 方法

- 基本思想：通过采样逼近真实的环境模型
  - 用多次轨迹的平均价值来逼近状态的真实价值
- 策略评估
  - Every-Visit：在每一个轨迹中，对每一次访问状态得到的价值都进行平均
    - $V(s_t)=\frac{V_{11}(s_t)+V_{12}(s_t)+V_{21}(s_t)}{3}$
  - First-Visit：在每一个轨迹中，只采用第一次访问状态得到的价值进行平均【常用这个】
    - $V(s_t)=\frac{V_{1}(s_t)+V_{2}(s_t)}{2}$
  - 补充：$V(s_t)$ 怎么算？
    - $G(s_t)=\gamma^tR_t+...+\gamma^nR_n$
    - **价值** 其实就是在到达这个状态之后你还能期望获得的奖赏
  - 想要在每一个轨迹结束时都更新 $V(s)$ 怎么办？
    - $N_{new}(s_t)=N(s_t)+1$
    - $V_{new}(s_t)=V(s_t)+\frac{1}{N_{new}(s_t)}(G(s_t)-V(s_t))$
- 迭代方法
  - 只有策略评估与动态规划不同，不采用 $Bellman$ 而是 $MC$
- 问题：能不能每走一步都可以更新一次 $V(s_t)$，而不用等到轨迹结束？
  - 时序差分法

### 时序差分法

- 也称 $TD$ 法
- $V(s_t)=V(s_t)+\alpha[R_{t}+\gamma V(s_{t+1})-V(s_t)]$
  - 由于没有走完，不能清楚地知道 $\frac{1}{N(s_t)}$，所以用一个 $\alpha\in (0,1]$ 代替
  - $V(s_{t+1})$：下一个状态的预估价值（上一次轨迹保留下来的值）
  - $\gamma$：折扣因子
- 区别
  - $MC$ 是 $Sampling$，只根据经验进行更新，所以要等到轨迹走完
  - 时序差分是 $Boostraping$，根据估计进行更新
- $TD(n)$
  - 上述的 $TD$ 法其实是 $TD(0)$
  - 想要看见更远的未来
  - $G^{(n)}_t=R_t+\gamma R_{t+1}+...+\gamma^{n-1}R_{t+n-1}+\gamma^n V(s_{t+n})$
  - 当 $n$ 越来越大，趋于完整轨迹时，等价于 $MD$
- $TD(\lambda)$
  - 那么怎样选择 $n$ 才能获得最优的效果呢？
    - 不选择，以所有步数作参考
    - 但对于每一个 $n$ 定义一个合适的权重 $(1-\lambda)\lambda^{n-1}$
  - 引入 $\lambda\in[0,1]$，定义 $G^\lambda_t=(1-\lambda)\sum_{n=1}^\infin\lambda^{n-1}G^{(n)}_t$ 为收获
  - 这样，迭代公式就转变为 $V(s_t)=V(s_t)+\alpha[G^\lambda_t-V(s_t)]$
  - 当 $\lambda=0$ 时为 $TD$；当 $\lambda=1$ 时为 $MC$
  - 算法
    - 初始化全部 $V(s),e(s)=0$
      - $e(s)$ 为 **效用**，代表该状态对后续状态的影响
    - 对每一个 episode
      - 初始化 $s$
      - 对 episode 中的每一步
        - 根据 $\varepsilon-greedy$ 选择 $a$
        - 执行 $a$，获得 $r$ 和 $s'$
        - $\Delta=r+\gamma V(s')-V(s)$
        - $e(s)=e(s)+1$
        - 对每一个 $s$
          - $V(s)=V(s)+\alpha*\Delta*e(s)$
          - $e(s)=\gamma*\lambda*e(s)$
        - $s\leftarrow s'$
      - 直至 $s$ 为终止状态

### Q-learning

- Q 表
  - 行为状态 $s$，列为行为 $a$
  - 值为期望
  - 我们希望对于每一个状态，只要选取期望最大的行为去做，就可以取得最好的结果

- 算法

```
R = [...](m*n 维)
探索率 = 0.8
学习率 = 0.8
折扣率 = 0.8

Q = [0](m*n 维)

while (学习未结束):
	s = 随机状态
	while (单次训练未结束):
		a = 策略(s)
		s' = 执行(a)
		Q[s,a] = bellman(s,a,s')
		s = s'
return Q
```

- $R$：奖励表，与 Q 表同维度
- 探索率：$\varepsilon$
  - 为了防止陷入局部最优：在 $s_i$ 处执行 $a_1$ 后得到正奖赏，其它动作的期望都是 0，导致以后每次处于这个状态都只会采用 $a_1$
  - 因此我们决定 $\varepsilon$ 的概率随机执行动作，$(1-\varepsilon)$ 的概率按照期望执行动作
- $bellman(s,a,s')$
  - $=(1-\alpha)*Q[s,a]+\alpha*(R[s,a]+\Upsilon*max_a Q[s',a])$
  - $\alpha$：学习率
    - 学习率越大，对之前训练效果的保留就越少
  - $\Upsilon$：折扣率
    - 折扣率越大，就越关心眼前的奖励而非记忆中将要获得的奖励

## 聚类

> Clustering

**聚类的好坏不存在绝对的标准**

### 概述

- 簇/类：内部相似，不同类之间不相似
- 相似性评价标准：距离
  - 把每个样本的特征向量看做样本空间中的点
  - 样本的相似性度量就是他们之间的距离
- 算法特征
  - 类并非事先给定，而是根据距离划分**（无监督）**
    - 潜在的自然分组结构
    - 感兴趣的关系
- 关键问题
  - 特征选取
  - 距离函数

### 距离

#### 常用度量函数

- 欧氏距离
  - $d(x_i,x_j)=\sqrt{(x_i-x_j)^T(x_i-x_j)}$
  - 在二维平面中即两点间距离
- 余弦相似性
  - $s(x_i,x_j)=\frac{x_i^Tx_j}{||x_i||||x_j||}$
  - 通过计算两个向量夹角的余弦值来评判它们是否大致指向同一方向
  - 范围在 $[-1,1]$
  - $||x||=\sqrt{x·x^T}$
- 曼哈顿距离
  - $d(x_i,x_j)=||x_i-x_j||_1$
- 切比雪夫距离
  - $d(x_i,x_j)=||x_i-x_j||_\infin$
- 马氏距离
  - $d(x_i,x_j)=\sqrt{(x_i-x_j)^TM(x_i-x_j))}$
  - $M$ 为样本总体的协方差矩阵
  - 要求
    - 样本数大于样本维数
    - 样本不共低维平面
  - 与欧氏距离区别
    - 欧氏距离对于所有特征同等看待
    - 马氏距离不关心原始数据的单位，还能排除特征之间相关性的干扰

#### 距离度量空间

- $(X,d)$：$X$ 是样本集合，$d$ 是 $X$ 上的度量函数（把 $X$ 中每一对 $x,y$ 映射到一个实数）
- 四条公理
  - 非负性：$d(x,y)\geq 0$
  - 唯一性：$d(x,y)=0\leftrightarrow x=y$
  - 对称性：$d(x,y)=d(y,x)$
  - 三角不等式：$d(x,z)\leq d(x,y)+d(y,z)$

### 聚类准则

- 试探方法
  - 定义一个阈值，超过这个值则形成新类
  - 当属于多个类时，按最近邻规则
- 聚类准则函数
  - 假设有待分类样本 $x_1,...,x_n$ 被划分为 $S_1,...,S_c$ 类
  - 则有准则函数 $J=\sum_{j=1}^cK$，$K=\sum_{x\in S_{j}}||x-m_j||^2$
    - $m_j$ 代表 $S_j$ 类的均值
    - $K$ 就是 $S_j$ 类中全部样本与均值的误差平方和
  - 因此我们的目标转化为求使 $J$ 最小的聚类形式

### 聚类方法

#### 基于试探

- **按最近邻规则的简单试探**
  - 定义
    - 数据样本：$x_1,...,x_n$
    - 阈值：$T$
    - 聚类中心：$z_1,z_2...$
  - 算法
    - 随机选取初始中心，如令 $z_1=x_1$
    - 对 $x_2$，计算 $d(z_1,x_2)$
      - 若 $d>T$，$x_2$ 成为 $z_2$
      - 若 $d\leq T$，$x_2$ 分到 $z_1$
    - 对 $x_3$，计算 $d(z_1,x_3),...,d(z_k,x_3)$
      - 若 $d(z_i,x_3)$ 和 $d(z_j,x_3)$ 都小于 $T$，选择更小的那个加入
    - 重复直到所有样本分类完毕
  - 影响因素
    - 第一个聚类中心
    - 样本排列次序！
    - 阈值
    - 样本几何性质
- **最大最小距离算法**
  - 思想
    - 以最大距离作为选出聚类中心的条件
  - 算法
    - 随机选取初始中心，如令 $z_1=x_1$
    - 若 $x_2$ 离 $x_1$ 最远，则选择其作为 $z_2$
    - 计算每个剩余样本 $i$ 和每个聚类中心 $j$ 之间的距离 $D_{ij}$
      - 对于每个 $j$，选出最小的 $D_{ij}$
      - 对于选出的 $j$ 个 $D$，选择其中最大的作为 $D$
        - 若 $D>\theta||z_1-z_2||$（ $\theta$ 自己定义，如 $\frac{1}{2}$ ），则令对应的 $x_i$ 成为新的聚类中心
        - 否则，寻找聚类中心的过程结束
    - 聚类中心寻找完毕后，按最近邻规则将剩余样本点分类
      - 最后还可以在每一类中计算均值，得到更具代表性的聚类中心

#### 系统聚类法

- 思想
  - 按照距离准则逐步分类，类别由多到少
- 算法
  - 初始样本 $x_1,...,x_n$ 自成一类分为 $n$ 类 $G_1^0,...,G_n^0$
  - 计算每个 $G$ 之间的距离，得到一个 $n\times n$ 的矩阵 $D^0$
  - 现在假设前一步已求得 $D^k$
    - 则求 $D^k$ 中最小的元素，若它是 $G_i^k$ 和 $G_j^k$ 之间的距离，则将它们合并为 $G_{i}^{k+1}$
    - 计算合并后 $G_1^{k+1},...,G_i^{k+1},...$ 得到的 $D^{k+1}$
  - 重复，直到满足以下其一
    - 达到目标聚类数上限
    - $D^k$ 中最小元素超过给定阈值
- $G_i$ 和 $G_j$ 之间的距离度量
  - 所有样本点间距离的最小值
  - 所有样本点间距离的最大值
  - 所有样本点间距离的平均值

#### 动态聚类法

- 思想
  - 初始选择若干聚类中心，再按照聚类准则使样本点向中心聚集，得到初始聚类
  - 然后判断聚类是否合理，若不合理则持续修改直至合理
- **K-means**
  - 定义
    - 聚类数量：$K$
    - 初始聚类中心：$c_1,...,c_K$
  - 算法
    - 初始化聚类中心
      - 随机坐标
      - 随机样本点
    - 对每个样本点，根据最近邻规则分到对应的聚类中心
    - 重新计算聚类中心
      - 聚类中全部样本的均值
    - 如果有样本点聚类改变，则迭代；否则，完成
  - 影响因素
    - 聚类数量
    - 初始聚类中心
    - 样本几何分布
- **K-means++**
  - 思想
    - 让初始聚类中心尽可能分开
  - 算法
    - 随机选择一个样本作为初始聚类中心 $c_1$
    - 计算每个样本 $i$ 与当前已有聚类中心 $j$ 之间的距离 $D_{ij}$
    - 对每个 $i$ 选出最小的 $D_{ij}$，记为 $D(i)$
    - 计算每个 $i$ 被选为下一个聚类中心的概率 $\frac{D(i)^2}{\sum_{k=1}^nD(k)^2}$
    - 按照 **轮盘法** 选出下一个聚类中心
      - 有概率 $p_1=0.3,p_2=0.4,p_3=0.3$，代表轮盘上的三个区域
      - 系统随机一个 $0-1$ 的数，如 $0.58$，代表指针的力量
      - $0.58-0.3=0.28>0$，指针还能转，继续
      - $0.28-0.4<0$，指针转不动了，选择 $2$
    - 重复直到选出 $K$ 个中心，后续步骤同 K-means
- **ISODATA**
  - 定义
    - 初始聚类数：$K_0$
    - 类最小元素数：$K_{min}$
    - 类间最小距离：$d_{min}$
    - 类内最大方差：$\sigma_{max}$
  - 算法
    - 随机选择 $K_0$ 个样本作为 $c_1,...,c_{K_0}$
    - 对每个样本，按照最近邻规则分类
    - 判断每个类中的元素数目是否小于 $K_{min}$
      - 若小于，丢弃该类，并将其中样本重新分类
    - 对每个 $c_i$，重新计算其聚类中心 $c_i=\frac{1}{|c_i|}\sum_{x\in c_i}x$（质心）
    - 若当前 $K\leq \frac{K_0}{2}$，做分裂
      - 对于每个类别
        - 计算全部样本在每个维度下的方差
        - 挑选出最大的方差 $\sigma$
        - 若 $\sigma>\sigma_{max}$ 且该类样本数大于等于 $2N_{min}$，进行分裂
      - 将需要分裂的类别 $i$ 分成两个子类
        - $c_i^1=c_i+\sigma$
        - $c_i^2=c_i-\sigma$
        - $K=K+1$
    - 若当前 $K \geq2K_0$，做合并
      - 计算所有聚类中心两两之间的距离，用矩阵 $D$ 表示（ $D(i,i)=0$ ）
      - 若 $D(i,j)<d_{min}$，合并 $i,j$
      - 合并类的聚类中心为 $c_{new}=\frac{1}{n_i+n_j}(n_ic_i+n_jc_j)$
        - $n_i$ 为聚类 $i$ 中的元素数
    - 若达到最大迭代次数则终止，否则回到 step2
  - 与 K-means 区别
    - K-means 适合已知类别数目，ISODATA 更灵活
    - ISODATA 可以在中途改变参数，可以更好地人机交互，利用中间结果经验
    - ISODATA 需要额外指定较多参数

#### 聚类评价▲

- 指标
  - 聚类中心之间的距离：尽可能大
  - 聚类中的样本数目：数目较少且距离较远时可能是噪声
  - 聚类中样本的距离方差：方差过大的样本可能应该分到其它类
- 常用指标
  - **标签未知**
  - $\Omega_i$ 表示一个类，$w_i$ 表示该类的中心，$K$ 表示类的总数
  - 紧密度
    - 越小表示类内约紧密（没有考虑类间聚类效果）
    - $\overline{CP}_k=\frac{1}{|\Omega_i|}\sum_{x\in \Omega_i}||x-w_i||$
    - $\overline{CP}=\frac{1}{K}\sum_{k=1}^K\overline{CP_k}$
  - 间隔度
    - 越大表示类间约分散（没有考虑类内聚类效果）
    - $\overline{SP}=\frac{2}{K^2-K}\sum_{i=1}^K\sum_{j=i+1}^K||w_i-w_j||^2$
  - 戴维森堡丁指数/分类适确性指标
    - 越小表示类内约紧凑，类间越分散（适用于欧氏距离，不适于环状分布）
    - $DBI=\frac{1}{K}\sum_{i=1}^Kmax_{i\neq j}(\frac{\overline{C}_i+\overline{C}_j}{||w_i-w_j||_2})$
  - 邓恩指数
    - 越大表示类内约紧凑，类间越分散（适用于离散样本，不适于环状分布）
    - $DVI=\frac{d_{min}}{d_{max}}$
      - $d_{min}$ 表示 任意两个类内元素间的最短距离 的最小值
      - $d_{max}$ 表示 任意类内任意元素间最大距离 的最大值
  - **标签已知**
  - 聚类准确率（CA）；兰德指数（RI）；调整兰德指数（ARI）；互信息（MI）；归一化互信息（NMI）

